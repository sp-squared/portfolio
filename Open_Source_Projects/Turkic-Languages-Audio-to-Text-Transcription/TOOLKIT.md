# Turkic Languages Audio-to-Text Transcription Toolkit

A comprehensive toolkit for Turkic language processing, including text classification, transliteration, and transcription utilities for **Bashkir**, **Kazakh**, and **Kyrgyz** languages.

[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Open Science](https://img.shields.io/badge/Open-Science-blue.svg)](https://en.wikipedia.org/wiki/Open_science)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

---

## üìã Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Quick Start](#quick-start)
- [Installation](#installation)
- [Usage](#usage)
  - [Language Classification](#language-classification)
  - [Transliteration](#transliteration)
  - [Transcript Cleaning](#transcript-cleaning)
- [Project Structure](#project-structure)
- [Training Your Own Models](#training-your-own-models)
- [Results](#results)
- [Documentation](#documentation)
- [Contributing](#contributing)
- [Citation](#citation)
- [License](#license)

---

## üéØ Overview

This project provides production-ready tools and trained models for working with three Turkic languages written in Cyrillic script:

| Language | Native Name | Speakers | Special Characters |
|----------|-------------|----------|-------------------|
| **Bashkir** | –ë–∞—à“°–æ—Ä—Ç | ~1.4M | “ô, “°, “£, “´, “Ø, “ª, ”ô, ”©, “ì |
| **Kazakh** | “ö–∞–∑–∞“õ | ~13M | ”ô, “ì, “õ, “£, ”©, “±, “Ø, “ª, —ñ |
| **Kyrgyz** | –ö—ã—Ä–≥—ã–∑ | ~4.5M | “£, ”©, “Ø |

### What's Included

‚úÖ **Pre-trained Language Classifier** - 100% accuracy on test set  
‚úÖ **Bidirectional Transliteration** - Latin ‚Üî Cyrillic conversion  
‚úÖ **Transcript Processing** - Clean NoteGPT transcripts  
‚úÖ **Training Scripts** - FastText, Scikit-Learn, and Transformers  
‚úÖ **Complete Documentation** - Guides, notebooks, and examples  
‚úÖ **6,000+ Training Samples** - From [MMTEB TurkicClassification](https://huggingface.co/datasets/mteb/TurkicClassification) dataset  

---

## ‚ú® Features

### üéì Language Classification

Automatically identify which Turkic language a text is written in:

```python
>>> classify_text("–ë–∏—à–∫–µ–∫ —à–∞–∞—Ä—ã–Ω–¥–∞ –∂–∞“£—ã –º–µ–∫—Ç–µ–ø –∞—á—ã–ª–¥—ã")
'kyrgyz' (confidence: 85.2%)

>>> classify_text("“ö–∞–∑–∞“õ—Å—Ç–∞–Ω–¥–∞ –∂–∞“£–∞ –∑–∞“£ “õ–∞–±—ã–ª–¥–∞–Ω–¥—ã")
'kazakh' (confidence: 90.5%)

>>> classify_text("–ë–∞—à“°–æ—Ä—Ç–æ—Å—Ç–∞–Ω –†–µ—Å–ø—É–±–ª–∏–∫–∞“ª—ã–Ω–¥–∞ –∫–æ–Ω—Ü–µ—Ä—Ç “Ø—Ç—Ç–µ")
'bashkir' (confidence: 69.5%)
```

**Three Model Options:**

- **Scikit-Learn** - Fast, 100% accuracy, 5 MB (‚úÖ Pre-trained included!)
- **FastText** - Balanced, ~98% accuracy, 15 MB
- **Transformers** - Best, ~99% accuracy, 500 MB

### üî§ Transliteration

Bidirectional Latin ‚Üî Cyrillic conversion with intelligent edge case handling:

```python
>>> latin_to_cyrillic("Qazaqstan", "kk")
'“ö–∞–∑–∞“õ—Å—Ç–∞–Ω'

>>> cyrillic_to_latin("–ë–∞—à“°–æ—Ä—Ç–æ—Å—Ç–∞–Ω", "ba")
'Bashqortostan'
```

**Handles 10+ Edge Cases:**

- Digraph ambiguity (sh ‚Üí —à, not —Å+h)
- Word-initial iotation (ye ‚Üí –µ at start)
- Soft sign apostrophes (' ‚Üí —å)
- Case preservation (Qazaq ‚Üí “ö–∞–∑–∞“õ)
- Russian loanwords support

### üìù Transcript Cleaning

Clean NoteGPT transcripts by removing timestamps:

```python
>>> clean_transcript("00:05:23 –ë“Ø–≥“Ø–Ω –±–∏–∑ —Ç–∞—Ä—ã—Ö —Ç—É—Ä–∞–ª—É—É —Å”©–π–ª”©—à”©–±“Ø–∑")
'–ë“Ø–≥“Ø–Ω –±–∏–∑ —Ç–∞—Ä—ã—Ö —Ç—É—Ä–∞–ª—É—É —Å”©–π–ª”©—à”©–±“Ø–∑'
```

Creates both plain and structured outputs with statistics.

---

## üöÄ Quick Start

### 1. Clone the Repository

```bash
git clone https://github.com/YOUR_USERNAME/Turkic-Languages-Audio-to-Text-Transcription.git
cd Turkic-Languages-Audio-to-Text-Transcription
```

### 2. Use the Pre-trained Classifier

```bash
cd project/training_data
python use_turkic_classifier.py
```

**Output:**

```
Text: –ë–∏—à–∫–µ–∫ —à–∞–∞—Ä—ã–Ω–¥–∞ –∂–∞“£—ã –º–µ–∫—Ç–µ–ø –∞—á—ã–ª–¥—ã...
  Language: KYRGYZ (confidence: 85.2%)
  Probabilities: Bashkir=5.3%, Kazakh=9.6%, Kyrgyz=85.2%
```

### 3. Try Transliteration

```python
from latin_to_cyrillic_turkic import TurkicTransliterator

trans = TurkicTransliterator()

# Latin ‚Üí Cyrillic
print(trans.latin_to_cyrillic("Qazaqstan", "kk"))
# Output: “ö–∞–∑–∞“õ—Å—Ç–∞–Ω

# Cyrillic ‚Üí Latin
print(trans.cyrillic_to_latin("–ë–∏—à–∫–µ–∫", "ky"))
# Output: Bishkek
```

---

## üì¶ Installation

### Prerequisites

- Python 3.8 or higher
- pip package manager

### Basic Installation

```bash
# Install required packages
pip install -r requirements.txt
```

### Optional Dependencies

```bash
# For FastText training
pip install fasttext

# For Transformer models (requires GPU for efficient training)
pip install transformers torch datasets accelerate

# For Jupyter notebooks
pip install jupyter notebook
```

---

## üíª Usage

### Language Classification

#### Option 1: Python API

```python
import pickle

# Load pre-trained model
with open('project/training_data/turkic_classifier.pkl', 'rb') as f:
    data = pickle.load(f)

model = data['model']
vectorizer = data['vectorizer']
labels = ['bashkir', 'kazakh', 'kyrgyz']

# Classify single text
text = "–ê–ª–º–∞—Ç—ã “õ–∞–ª–∞—Å—ã–Ω–¥–∞ –∂–∞“£–∞ –∂–æ–±–∞ —ñ—Å–∫–µ “õ–æ—Å—ã–ª–¥—ã"
X = vectorizer.transform([text])
prediction = model.predict(X)[0]
confidence = model.predict_proba(X)[0][prediction]

print(f"Language: {labels[prediction]}")
print(f"Confidence: {confidence:.1%}")
```

#### Option 2: Command Line

```bash
cd project/training_data
python use_turkic_classifier.py
```

#### Option 3: Batch Processing

```python
texts = [
    "–ë–∏—à–∫–µ–∫ —à–∞–∞—Ä—ã–Ω–¥–∞ –∂–∞“£—ã –º–µ–∫—Ç–µ–ø –∞—á—ã–ª–¥—ã",
    "“ö–∞–∑–∞“õ—Å—Ç–∞–Ω–¥–∞ –∂–∞“£–∞ –∑–∞“£ “õ–∞–±—ã–ª–¥–∞–Ω–¥—ã",
    "–ë–∞—à“°–æ—Ä—Ç–æ—Å—Ç–∞–Ω –†–µ—Å–ø—É–±–ª–∏–∫–∞“ª—ã–Ω–¥–∞ –∫–æ–Ω—Ü–µ—Ä—Ç “Ø—Ç—Ç–µ"
]

X = vectorizer.transform(texts)
predictions = model.predict(X)

for text, pred in zip(texts, predictions):
    print(f"{labels[pred]}: {text[:50]}...")
```

---

### Transliteration

#### Basic Usage

```python
from latin_to_cyrillic_turkic import TurkicTransliterator

trans = TurkicTransliterator()

# Specify language: "ba" (Bashkir), "kk" (Kazakh), "ky" (Kyrgyz)
cyrillic = trans.latin_to_cyrillic("Salam", "kk")
latin = trans.cyrillic_to_latin("–°–∞–ª–∞–º", "kk")

print(cyrillic)  # –°–∞–ª–∞–º
print(latin)     # Salam
```

#### Language-Specific Characters

```python
# Bashkir special characters
trans.latin_to_cyrillic("bashqort", "ba")  # –±–∞—à“°–æ—Ä—Ç

# Kazakh special characters  
trans.latin_to_cyrillic("qazaq", "kk")     # “õ–∞–∑–∞“õ

# Kyrgyz special characters
trans.latin_to_cyrillic("qyrgyz", "ky")    # –∫—ã—Ä–≥—ã–∑
```

#### Interactive Jupyter Notebook

```bash
jupyter notebook project/training_data/turkic_transliteration.ipynb
```

Includes:

- Interactive examples
- All edge cases demonstrated
- Character mapping tables
- Practical applications

---

### Transcript Cleaning

#### Clean NoteGPT Transcripts

```python
from clean_transcript import clean_transcript

input_file = "NoteGPT_TRANSCRIPT_xxxxxxxxxxxxx.txt"
output_file = "cleaned_transcript.txt"

# Process transcript
clean_transcript(input_file, output_file)
```

**Creates:**

- `cleaned_transcript.txt` - Pure text (no timestamps)
- `cleaned_transcript_structured.txt` - Numbered segments with timestamps
- Statistics: segments, words, characters

---

## üìÅ Project Structure

```
Turkic-Languages-Audio-to-Text-Transcription/
‚îú‚îÄ‚îÄ audio/                          # Input audio files (.m4a, .wav, .mp3)
‚îú‚îÄ‚îÄ scripts/                        # Main executable scripts
‚îÇ   ‚îú‚îÄ‚îÄ whisper_transcribe_and_correct.py    # Main transcription pipeline
‚îÇ   ‚îú‚îÄ‚îÄ kazakh_to_bashkir_corrector.py       # Orthography corrector
‚îÇ   ‚îú‚îÄ‚îÄ clean_vad_transcript.py              # Transcript cleaning
‚îÇ   ‚îî‚îÄ‚îÄ train_sklearn_turkic.py              # Train language classifier
‚îú‚îÄ‚îÄ output/                         # Generated transcription results
‚îú‚îÄ‚îÄ project/
‚îÇ   ‚îú‚îÄ‚îÄ data/                       # Training datasets (~16MB)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bashkir_clean_cyrillic_base.txt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ kazakh_clean_cyrillic_base.txt
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ kyrgyz_clean_cyrillic_base.txt
‚îÇ   ‚îú‚îÄ‚îÄ docs/                       # Documentation
‚îÇ   ‚îî‚îÄ‚îÄ training_scripts/           # Model training utilities
‚îÇ       ‚îú‚îÄ‚îÄ use_turkic_classifier.py
‚îÇ       ‚îú‚îÄ‚îÄ train_fasttext_turkic.py
‚îÇ       ‚îî‚îÄ‚îÄ train_transformer.py
‚îú‚îÄ‚îÄ training_data/                  # Processed training samples
‚îÇ   ‚îî‚îÄ‚îÄ langid_sklearn_model.pkl    # Trained classifier (896 KB)
‚îú‚îÄ‚îÄ LICENSE                         # MIT License
‚îî‚îÄ‚îÄ README.md                       # This file
```

---

## üèãÔ∏è Training Your Own Models

### Option 1: Scikit-Learn (Recommended)

**Fast training, great accuracy, no GPU needed**

```bash
cd project/training_data
python train_sklearn_turkic.py
```

**Training time:** 30 seconds  
**Expected accuracy:** 100% on this dataset  
**Model size:** 5 MB

---

### Option 2: FastText

**Balanced approach for production systems**

```bash
pip install fasttext
cd project/training_data
python train_fasttext_turkic.py
```

**Training time:** 5-10 minutes  
**Expected accuracy:** ~98%  
**Model size:** 15 MB

---

### Option 3: Transformers (BERT/XLM-RoBERTa)

**Maximum accuracy, requires GPU**

```bash
pip install transformers torch datasets accelerate
cd project/training_data
python train_transformer.py
```

**Training time:** 2-4 hours (with GPU)  
**Expected accuracy:** ~99%+  
**Model size:** 500 MB

---

## üìä Results

### Classification Performance

**Scikit-Learn Model (Pre-trained)**

```
Test Accuracy: 100.00%

Classification Report:
              precision    recall  f1-score   support
     bashkir       1.00      1.00      1.00       307
      kazakh       1.00      1.00      1.00       308
      kyrgyz       1.00      1.00      1.00       307

    accuracy                           1.00       922
```

**Confusion Matrix:**

```
          Bashkir  Kazakh  Kyrgyz
Bashkir       307       0       0
Kazakh          0     308       0
Kyrgyz          0       0     307
```

### Model Comparison

| Model | Training Time | Accuracy | Size | GPU Required | Offline |
|-------|--------------|----------|------|--------------|---------|
| **Scikit-Learn** | 30 sec | 100%* | 5 MB | ‚ùå | ‚úÖ |
| **FastText** | 5-10 min | ~98% | 15 MB | ‚ùå | ‚úÖ |
| **Transformers** | 2-4 hours | ~99%+ | 500 MB | ‚úÖ | ‚ùå |

*100% on this specific dataset - generalization may vary

---

## üìö Documentation

### Main Guides

- **[README_TRAINING.md](project/training_data/README_TRAINING.md)** - Complete training guide
- **[QUICK_START.md](project/training_data/QUICK_START.md)** - Fast setup instructions
- **[EDITING_GUIDE.md](project/training_data/EDITING_GUIDE.md)** - File path configuration

### Technical Documentation

- **[fine_tuning_guide.md](project/training_data/fine_tuning_guide.md)** - Deep dive into model fine-tuning
- **[transliteration_edge_cases.md](project/training_data/transliteration_edge_cases.md)** - Transliteration details
- **[code_breakdown.md](project/training_data/code_breakdown.md)** - Line-by-line code explanation

### Interactive Learning

- **[turkic_transliteration.ipynb](project/training_data/turkic_transliteration.ipynb)** - Jupyter notebook with examples

---

## ü§ù Contributing

Contributions are welcome! Here's how you can help:

### Adding Training Data

1. Add more text samples to the `.txt` files
2. Ensure UTF-8 encoding
3. One sample per line
4. Retrain models

### Adding New Languages

1. Create new `language_clean_cyrillic_base.txt` file
2. Update `train_*.py` scripts with new language code
3. Add character mappings to transliteration
4. Train and test models

### Improving Models

1. Try different hyperparameters
2. Experiment with other models (e.g., DistilBERT, ELECTRA)
3. Implement data augmentation
4. Share your results!

### Bug Reports & Feature Requests

Open an issue on GitHub with:

- Clear description
- Steps to reproduce (for bugs)
- Expected vs actual behavior
- Python version and OS

---

## ‚ùì FAQ

**Q: Which model should I use?**  
A: Start with the pre-trained Scikit-Learn model. It's fast, accurate, and works offline.

**Q: Can this work for other Turkic languages?**  
A: Yes! Add training data for the language and retrain. Works for any Turkic language in Cyrillic or Latin script.

**Q: What about audio transcription (Whisper)?**  
A: This project focuses on text processing. For speech-to-text, you'll need audio files + transcripts and Whisper fine-tuning (different approach).

**Q: How do I add more training data?**  
A: Simply append more text samples to the `.txt` files (one per line) and retrain.

**Q: Can I use this commercially?**  
A: Yes, under the MIT license. See [LICENSE](LICENSE) for details.

**Q: How accurate is the transliteration?**  
A: Round-trip accuracy is very high for standard text. Some ambiguity exists in foreign words and names.

**Q: Does this work on Windows/Mac/Linux?**  
A: Yes! Python code is cross-platform. Use the `_FIXED` versions for correct file paths on Windows.

---

## üìà Roadmap

- [ ] Web API (Flask/FastAPI)
- [ ] Docker container
- [ ] Additional Turkic languages (Tatar, Uyghur, Uzbek)
- [ ] Real-time classification endpoint
- [ ] Fine-tuned Whisper models for speech recognition
- [ ] Browser extension for automatic transliteration
- [ ] Mobile app (iOS/Android)

---

## üìñ Citation

If you use this project or the TurkicClassification dataset in your research, please cite the following papers.

> **Note:** GitHub also provides a "Cite this repository" button using the [CITATION.cff](CITATION.cff) file.

### TurkicClassification Dataset (MMTEB)

```bibtex
@article{enevoldsen2025mmtebmassivemultilingualtext,
  title={MMTEB: Massive Multilingual Text Embedding Benchmark},
  author={Kenneth Enevoldsen and Isaac Chung and Imene Kerboua and M√°rton Kardos and Ashwin Mathur and David Stap and Jay Gala and Wissam Siblini and Dominik Krzemi≈Ñski and Genta Indra Winata and Saba Sturua and Saiteja Utpala and Mathieu Ciancone and Marion Schaeffer and Gabriel Sequeira and Diganta Misra and Shreeya Dhakal and Jonathan Rystr√∏m and Roman Solomatin and √ñmer √áaƒüatan and Akash Kundu and Martin Bernstorff and Shitao Xiao and Akshita Sukhlecha and Bhavish Pahwa and Rafa≈Ç Po≈õwiata and Kranthi Kiran GV and Shawon Ashraf and Daniel Auras and Bj√∂rn Pl√ºster and Jan Philipp Harries and Lo√Øc Magne and Isabelle Mohr and Mariya Hendriksen and Dawei Zhu and Hippolyte Gisserot-Boukhlef and Tom Aarsen and Jan Kostkan and Konrad Wojtasik and Taemin Lee and Marek ≈†uppa and Crystina Zhang and Roberta Rocca and Mohammed Hamdy and Andrianos Michail and John Yang and Manuel Faysse and Aleksei Vatolin and Nandan Thakur and Manan Dey and Dipam Vasani and Pranjal Chitale and Simone Tedeschi and Nguyen Tai and Artem Snegirev and Michael G√ºnther and Mengzhou Xia and Weijia Shi and Xing Han L√π and Jordan Clive and Gayatri Krishnakumar and Anna Maksimova and Silvan Wehrli and Maria Tikhonova and Henil Panchal and Aleksandr Abramov and Malte Ostendorff and Zheng Liu and Simon Clematide and Lester James Miranda and Alena Fenogenova and Guangyu Song and Ruqiya Bin Safi and Wen-Ding Li and Alessia Borghini and Federico Cassano and Hongjin Su and Jimmy Lin and Howard Yen and Lasse Hansen and Sara Hooker and Chenghao Xiao and Vaibhav Adlakha and Orion Weller and Siva Reddy and Niklas Muennighoff},
  publisher = {arXiv},
  journal={arXiv preprint arXiv:2502.13595},
  year={2025},
  url={https://arxiv.org/abs/2502.13595},
  doi = {10.48550/arXiv.2502.13595},
}
```

### MTEB Framework

```bibtex
@article{muennighoff2022mteb,
  author = {Muennighoff, Niklas and Tazi, Nouamane and Magne, Lo√Øc and Reimers, Nils},
  title = {MTEB: Massive Text Embedding Benchmark},
  publisher = {arXiv},
  journal={arXiv preprint arXiv:2210.07316},
  year = {2022},
  url = {https://arxiv.org/abs/2210.07316},
  doi = {10.48550/ARXIV.2210.07316},
}
```

If you use this work in your research, please cite:

```bibtex
@software{turkic_asr_2025,
  author = {Colin Morris},
  title = {Turkic Languages Audio-to-Text Transcription: 
           Deterministic ASR Pipeline for Bashkir, Kazakh, and Kyrgyz},
  year = {2025},
  url = {https://github.com/sp-squared/Turkic-Languages-Audio-to-Text-Transcription},
  note = {Open-source ASR pipeline with deterministic orthography correction}
}
```

---

## üôè Acknowledgments

- Training data sourced from the **TurkicClassification** dataset, part of the [MMTEB benchmark](https://arxiv.org/abs/2502.13595) (Enevoldsen et al., 2025)
- Dataset available on [HuggingFace](https://huggingface.co/datasets/mteb/TurkicClassification)
- Built with [Scikit-Learn](https://scikit-learn.org/), [FastText](https://fasttext.cc/), and [Transformers](https://huggingface.co/transformers/)
- Inspired by the need for better Turkic language NLP tools

---

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## üìß Contact

- **GitHub Issues:** [Report bugs or request features](https://github.com/sp-squared/Turkic-Languages-Audio-to-Text-Transcription/issues)
- **Pull Requests:** Contributions welcome!

---

## ‚≠ê Star This Repo

If you find this project useful, please consider giving it a star! It helps others discover this work.

---

<div align="center">

**Made with ‚ù§Ô∏è for the Turkic language community**

**"This is the frontier."** üöÄ

[‚¨Ü Back to Top](#turkic-languages-audio-to-text-transcription)

</div>
